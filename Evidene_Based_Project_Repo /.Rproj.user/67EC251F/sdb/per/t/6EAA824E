{
    "contents" : "\n##Step-by-step script guide how to mine info from a twitter user\n##From http://www.inside-r.org/howto/mining-twitter-airline-consumer-sentiment?##mkt_tok=3RkMMJWWfF9wsRoku6zLZKXonjHpfsX/##7OgtWaOg38431UFwdcjKPmjr1YIBTcp0dvycMRAVFZl5nR5dDO%2BZaZRJ9fteBEyiTS/2jqY%3D\n\n##BASIC STUFF\n##Load libraries\n##dependicies load automatically\nlibrary(twitteR)\n\n##2-connect to a user \n##example using @VinceKuraitis(Health Care Related)\n\nkuraitis.tweets = searchTwitter('@VinceKuraitis', n=20)\n\n#check length\nlength(kuraitis.tweets)\n\n#check type\nclass(kuraitis.tweets)\n\n#check last user name\ntweet$getScreenName()\n\n#check last tweet\ntweet$getText()\n\n##EXTRACT TEXT FROM TWEETS\n##use the plyr package, it makes naming the functions cleaner\n\nlibrary(plyr)\n\n##Write a function to process the data\n##Use the apply family of functions apply() lapply(), mapply(), sapply(),\n##tapply(), vapply(), etc\n##use the getText() on each objet\n##first letter = from state ex list second letter = to state ex array plyr ##functions always end in ply\n\nkuraitis.text = laply(kuraitis.tweets, function(t)t$getText())\nlength(kuraitis.text)\nhead(kuraitis).text,5)##loads 5 tweets\nclass(kuraitis.tweets)\n\n##ESTIMATING SENTIMENT:The ALgorithm\n##KISS IT: counting positive words and negative words\n##NExt Time we'll make a better algorithm, if there is time. \n##subtract occurances of negative words from number of positive\n##larger negative scores receive a negative sentiment\n##neutral scorces receive a number close to zero\n##larger positive scores receive a positive sentiment\n\n##LOADING THE OPINION LEXICON\n##http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar\n##Scan both documents in order to score text\n##the below objects make simple character vectors\n##load lexicons into R-studio\nhu.liu.pos = scan('/Users/jonathanschaller/Desktop/informaticsrepo/Evidene_Based_Project_Repo\\ /opinion-lexicon-English/positive-words.txt', what='character',comment.char=';')\n\nhu.liu.neg = scan('/Users/jonathanschaller/Desktop/informaticsrepo/Evidene_Based_Project_Repo\\ /opinion-lexicon-English/negative-words.txt', what='character',comment.char=';')\n\n##Run a couple checks\nclass(hu.liu.neg)\nclass(hu.liu.pos)\nlength(hu.liu.neg)\nlength(hu.liu.pos)\n\n##update lexicon with industry and twitter specific keywords\n## c() = combine function\npos.words = c(hu.liu.pos, 'efficient')\nneg.words = c(hu.liu.neg, 'expensive')\n\n##IMPLEMENT THE SCORING ALGORITHM TO SCORE SENTIMENT\n##use our score.sentiment() function which applies the laply() \n\nscore.sentiment = function(sentences, pos.words, neg.words, .progress='none')\n{\n\trequire(plyr)\n\trequire(stringr)\n#we got a vector of sentences. plyr will handle a list\n#or a vector as an \"l\" for us\n#we want a simple array of scores bac, so we use\n#\"l\", + \"a\", + \"ply\" = \"laply\":\nscores = laply(sentences, function(sentences, pos.words, neg.words){\n#clean up sentences with R's regex-driven global substitute, gsub():\nsentence = gsub('[[:punct:]]',\",sentence)\nsentence = gsub('[[:cntrl:]]',\",sentence)\nsentence = gsub('\\\\d+',\", sentence)\n#and convert to lower case\nsentence = tolower(sentence)\n#split into words.str_split is in the stringer package\nword.list = str_split(sentence, '\\\\s+')\n#sometimes a list() is one level of hierarchy too much\nwords = unlist(word.list)\n#compare our words to the dictonaries of positive & negative terms\npos.matches = match(words, pos.words)\nneg.matches = match(words, neg.words)\n#match() returns the position of the matches term or NA\n##we want TRUE/FALSE\npos.matches = !is.na(pos.matches)\nneg.matches = !is.na(neg.matches)\n#conviently, TRUE/FALSE will be treated as 1/0 by sum()\nscore = sum(pos.matches)- sum(neg.matches)\nscores.df = data.frame(score=scores, text=sentences)\nreturn(scores.df)}, pos.words, neg.words, .progress=.progress)\nscores.df = data.rame(score=scores,text=sentences)\nreturn(scores.df)\n}\n\n\n\n",
    "created" : 1360126479681.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3345973117",
    "id" : "6EAA824E",
    "lastKnownWriteTime" : 1360126847,
    "path" : "~/Desktop/informaticsrepo/Evidene_Based_Project_Repo /Rcodes/Raw_Scripts/minefromtwitter.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}