library(twitteR)
library(twitteR)
library("RJSONIO", lib.loc="/Library/Frameworks/R.framework/Versions/2.15/Resources/library")
detach("package:RJSONIO", unload=TRUE)
##Breens Sentiment Approach
library(twitteR)
library(plyr)
library(plyr)
library(twitteR)
library(stringr)
##loads need libraries
## defines functions to score.sentiment
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{}
{}
library(plyr)
library(twitteR)
library(stringr)
##loads sentiment related libraries
##maes function score.sentiment
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{}
{}
{ }
{}c
library(plyr)
library(twitteR)
library(stringr)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
asdf
farzard.tweets = searchTwitter('@AWade711', n=1500)
farzard.tweets = searchTwitter('@AWade711', n=5)
fix(farzard.tweets)
library(twitteR)
kuraitis.tweets = searchTwitter('@VinceKuraitis', n=20)
fix(kuraitis.tweets)
length(uraitis.tweets)
length(kuraitis.tweets)
class(kuraitis.tweets)
tweet = kuraitis.tweets[[1]]
class(tweet)
tweet$getScreenName()
tweet$getText()
kuraitis.text = laply(kuraitis.tweets, function(t)t$getText())
tweet$getText()
library(plyr)
kuraitis.text = laply(kuraitis.tweets, function(t)t$getText())
length(kuraitis.text)
head(kuraitis.text,5)
class(kuraitis.tweets)
hu.liu.pos = scan('./opinion-lexicon-English/positive-words.txt',what='character', comment.char=';')
hu.liu.neg = scan('./opinion-lexicon-English/negative-words.txt',what='character', comment.char=';')
class(hu.liu.neg)
class(hu.liu.pos)
pos.words = c(hu.liu.pos, 'efficient')
neg.words = c(hu.liu.neg, 'expensive')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{}
{}
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
#we got a vector of sentences. plyr will handle a list
#or a vector as an "l" for us
#we want a simple array of scores bac, so we use
#"l", + "a", + "ply" = "laply":
scores = laply(sentences, function(sentences, pos.words, neg.words){
#clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]',",sentence)
sentence = gsub('[[:cntrl:]]',",sentence)
sentence = gsub('\\d+',", sentence)
#and convert to lower case
sentence = tolower(sentence)
#split into words.str_split is in the stringer package
word.list = str_split(sentence, '\\s+')
#sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
#compare our words to the dictonaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
#match() returns the position of the matches term or NA
##we want TRUE/FALSE
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
#conviently, TRUE/FALSE will be treated as 1/0 by sum()
score = sum(pos.matches)- sum(neg.matches)
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)}, pos.words, neg.words, .progress=.progress)
scores.df = data.rame(score=scores,text=sentences)
return(scores.df)
}
{}
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
library(twitteR)
kuraitis.tweets = searchTwitter('@VinceKuraitis', n=20)
length(kuraitis.tweets)
class(kuraitis.tweets)
tweet$getScreenName()
tweet$getText()
library(plyr)
kuraitis.text = laply(kuraitis.tweets, function(t)t$getText())
length(kuraitis.text)
head(kuraitis).text,5)
class(kuraitis.tweets)
head(kuraitis).text,5
head(kuraitis.text,5)
hu.liu.pos = scan('/Users/jonathanschaller/Desktop/informaticsrepo/Evidene_Based_Project_Repo\ /opinion-lexicon-English/positive-words.txt', what='character',comment.char';')
hu.liu.pos = scan('/opinion-lexicon-English/positive-words.txt',what='character',comment.char';')
hu.liu.pos = scan('/Users/jonathanschaller/Desktop/informaticsrepo/Evidene_Based_Project_Repo\ /opinion-lexicon-English/positive-words.txt',what='character',comment.char';')
hu.liu.pos = scan('/opinion-lexicon-English/positive-words.txt',what='character',comment.char=';')
hu.liu.pos = scan('/Users/jonathanschaller/Desktop/informaticsrepo/Evidene_Based_Project_Repo\ /opinion-lexicon-English/positive-words.txt',what='character',comment.char=';')
hu.liu.neg = scan('/Users/jonathanschaller/Desktop/informaticsrepo/Evidene_Based_Project_Repo\ /opinion-lexicon-English/negative-words.txt',what='character',comment.char=';')
class(hu.liu.neg)
class(hu.liu.pos)
class(hu.liu.neg)
class(hu.liu.pos)
length(hu.liu.neg)
length(hu.liu.pos)
pos.words = c(hu.liu.pos, 'efficient')
neg.words = c(hu.liu.neg, 'expensive')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list or a vector as an "l" for us
# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
#' @param pos.words vector of words of postive sentiment
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of sentences. plyr will handle a list or a vector as an "l" for us
# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
scores = laply(sentences, function(sentence, pos.words, neg.words) {
# clean up sentences with R's regex-driven global substitute, gsub():
sentence = gsub('[[:punct:]]', '', sentence)
sentence = gsub('[[:cntrl:]]', '', sentence)
sentence = gsub('\\d+', '', sentence)
# and convert to lower case:
sentence = tolower(sentence)
# split into words. str_split is in the stringr package
word.list = str_split(sentence, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
pos.matches = match(words, pos.words)
neg.matches = match(words, neg.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=sentences)
return(scores.df)
}
score = sum(pos.matches) - sum(neg.matches)
class(hu.liu.neg)
class(hu.liu.pos)
length(hu.liu.neg)
length(hu.liu.pos)
score = sum(pos.matches) - sum(neg.matches)
score = sum(pos.matches) - sum(neg.matches)
class(hu.liu.neg)
class(hu.liu.pos)
length(hu.liu.neg)
length(hu.liu.pos)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
class(hu.liu.neg)
class(hu.liu.pos)
length(hu.liu.neg)
length(hu.liu.pos)
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
class(hu.liu.neg)
class(hu.liu.pos)
length(hu.liu.neg)
length(hu.liu.pos)
projectDir = getwd()
codeDir = file.path(projectDir, 'R')
dataDir = file.path(projetDir, 'data')
getwd()
projectDir = getwd()
codeDir = file.path(projectDir, 'R')
dataDir = file.path(projectDir, 'data')
outputDir = file.path(projectDir, 'output')
VERBOSE = TRUE
if (VERBOSE)
if(VERBOSE)
VERBOSE = TRUE
if VERBOSE
if [VERBOSE]
if (VERBOSE)
